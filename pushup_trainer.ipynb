{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a1633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d5462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"Dataset\"\n",
    "MODEL_PATH = \"pushup_cnn_lstm.h5\"\n",
    "IMG_SIZE = 64\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8abcd981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_video_frames_from_folder(folder, label):\n",
    "#     frames = []\n",
    "#     labels = []\n",
    "#     for filename in os.listdir(folder):\n",
    "#         file_path = os.path.join(folder, filename)\n",
    "#         cap = cv2.VideoCapture(file_path)\n",
    "#         frame_list = []\n",
    "#         while True:\n",
    "#             ret, frame = cap.read()\n",
    "#             if not ret:\n",
    "#                 break\n",
    "#             frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "#             frame = img_to_array(frame) / 255.0\n",
    "#             frame_list.append(frame)\n",
    "#         cap.release()\n",
    "#         if len(frame_list) > 0:\n",
    "#             frames.append(frame_list)\n",
    "#             labels.append(label)\n",
    "#     return frames, labels\n",
    "\n",
    "# def load_dataset():\n",
    "#     print(\"ðŸ“‚ Loading dataset...\")\n",
    "#     correct_frames, correct_labels = load_video_frames_from_folder(os.path.join(DATASET_PATH, \"Correct sequence\"), 1)\n",
    "#     wrong_frames, wrong_labels = load_video_frames_from_folder(os.path.join(DATASET_PATH, \"Wrong sequence\"), 0)\n",
    "\n",
    "#     frames = correct_frames + wrong_frames\n",
    "#     labels = correct_labels + wrong_labels\n",
    "\n",
    "#     # Pad/truncate sequences to same length\n",
    "#     max_len = max(len(f) for f in frames)\n",
    "#     X = np.zeros((len(frames), max_len, IMG_SIZE, IMG_SIZE, 3))\n",
    "#     for i, seq in enumerate(frames):\n",
    "#         for j in range(min(len(seq), max_len)):\n",
    "#             X[i, j] = seq[j]\n",
    "#     y = np.array(labels)\n",
    "#     print(\"âœ… Dataset loaded successfully.\")\n",
    "#     return X, y\n",
    "\n",
    "TARGET_FRAMES = 60   # or whatever number you want\n",
    "\n",
    "def reduce_frames(frame_list, target_frames=TARGET_FRAMES):\n",
    "    total = len(frame_list)\n",
    "    indices = np.linspace(0, total - 1, target_frames).astype(int)\n",
    "    reduced = [frame_list[i] for i in indices]\n",
    "    return np.array(reduced)\n",
    "\n",
    "\n",
    "def load_video_frames_from_folder(folder, label):\n",
    "    frames, labels = [], []\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        cap = cv2.VideoCapture(file_path)\n",
    "        extracted = []\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "            frame = img_to_array(frame) / 255.0\n",
    "            extracted.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        if len(extracted) >= 5:\n",
    "            frames.append(reduce_frames(extracted))\n",
    "            labels.append(label)\n",
    "\n",
    "    return frames, labels\n",
    "\n",
    "\n",
    "# def load_dataset():\n",
    "#     print(\"ðŸ“‚ Loading dataset...\")\n",
    "\n",
    "#     correct_frames, correct_labels = load_video_frames_from_folder(\n",
    "#         os.path.join(DATASET_PATH, \"Correct sequence\"), 1)\n",
    "\n",
    "#     wrong_frames, wrong_labels = load_video_frames_from_folder(\n",
    "#         os.path.join(DATASET_PATH, \"Wrong sequence\"), 0)\n",
    "\n",
    "#     X = np.array(correct_frames + wrong_frames)\n",
    "#     y = np.array(correct_labels + wrong_labels)\n",
    "\n",
    "#     print(\"New X shape:\", X.shape)  # (N, 30, 64, 64, 3)\n",
    "#     print(\"Unique labels:\", set(y))\n",
    "\n",
    "#     print(\"âœ… Dataset loaded successfully.\")\n",
    "#     return X, y\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    print(\"ðŸ“‚ Loading dataset...\")\n",
    "\n",
    "    # Load raw frames\n",
    "    correct_frames, correct_labels = load_video_frames_from_folder(\n",
    "        os.path.join(DATASET_PATH, \"Correct sequence\"), 1)\n",
    "\n",
    "    wrong_frames, wrong_labels = load_video_frames_from_folder(\n",
    "        os.path.join(DATASET_PATH, \"Wrong sequence\"), 0)\n",
    "\n",
    "    frames = correct_frames + wrong_frames\n",
    "    labels = correct_labels + wrong_labels\n",
    "\n",
    "    # -----------------------------\n",
    "    # âš ï¸ DYNAMIC FRAME HANDLING\n",
    "    # -----------------------------\n",
    "    # If model exists â†’ get expected frame count from model\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        print(\"ðŸ§  Pretrained model detected â†’ using its input sequence length.\")\n",
    "        model = load_model(MODEL_PATH)\n",
    "        max_len = model.input_shape[1]     # LSTM expected timesteps\n",
    "        print(f\"Model expects {max_len} frames.\")\n",
    "    else:\n",
    "        print(\"ðŸ“Œ No pretrained model â†’ using longest video sequence.\")\n",
    "        max_len = max(len(f) for f in frames)\n",
    "        print(f\"Max frame length found: {max_len}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # PAD / TRUNCATE EACH VIDEO\n",
    "    # -----------------------------\n",
    "    X = np.zeros((len(frames), max_len, IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "    for i, seq in enumerate(frames):\n",
    "        seq_len = len(seq)\n",
    "\n",
    "        if seq_len >= max_len:\n",
    "            # truncate extra frames\n",
    "            X[i] = np.array(seq[:max_len])\n",
    "        else:\n",
    "            # pad remaining frames with zeros\n",
    "            X[i, :seq_len] = np.array(seq)\n",
    "\n",
    "    y = np.array(labels)\n",
    "\n",
    "    print(\"New X shape:\", X.shape)\n",
    "    print(\"Unique labels:\", set(y))\n",
    "    print(\"âœ… Dataset loaded successfully.\\n\")\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2a96ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=input_shape),\n",
    "        TimeDistributed(MaxPooling2D((2, 2))),\n",
    "\n",
    "        TimeDistributed(Conv2D(64, (3, 3), activation='relu')),\n",
    "        TimeDistributed(MaxPooling2D((2, 2))),\n",
    "\n",
    "        TimeDistributed(Flatten()),\n",
    "        LSTM(64, return_sequences=False),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccbfa044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Pre-trained model found! Loading existing model...\n",
      "âœ… Model loaded successfully.\n",
      "ðŸ“‚ Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Pretrained model detected â†’ using its input sequence length.\n",
      "Model expects 20 frames.\n",
      "New X shape: (100, 20, 64, 64, 3)\n",
      "Unique labels: {0, 1}\n",
      "âœ… Dataset loaded successfully.\n",
      "\n",
      "\n",
      "ðŸ“Š Evaluating Model...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742ms/step\n",
      "Raw prediction shape: (20, 2)\n",
      "\n",
      "Accuracy: 0.3\n",
      "Precision: 0.5\n",
      "Recall: 0.07142857142857142\n",
      "F1 Score: 0.125\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.83      0.42         6\n",
      "           1       0.50      0.07      0.12        14\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.39      0.45      0.27        20\n",
      "weighted avg       0.43      0.30      0.21        20\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 5  1]\n",
      " [13  1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "from sklearn.utils import shuffle   # âœ… FIX: Now imported properly\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    print(\"\\nðŸ“Š Evaluating Model...\")\n",
    "\n",
    "    y_pred_raw = model.predict(X_test)\n",
    "    print(\"Raw prediction shape:\", y_pred_raw.shape)\n",
    "\n",
    "    # -------- FIXED LOGIC --------\n",
    "    # Case 1: output is (batch, 1)\n",
    "    if y_pred_raw.ndim == 2 and y_pred_raw.shape[1] == 1:\n",
    "        y_pred_raw = y_pred_raw.flatten()\n",
    "\n",
    "    # Case 2: output is (batch, seq_len > 1)\n",
    "    elif y_pred_raw.ndim == 2 and y_pred_raw.shape[1] > 1:\n",
    "        y_pred_raw = y_pred_raw.mean(axis=1)\n",
    "\n",
    "    # Safety: match y_test length\n",
    "    y_pred_raw = y_pred_raw[:len(y_test)]\n",
    "\n",
    "    # Convert to binary\n",
    "    y_pred = (y_pred_raw > 0.5).astype(int)\n",
    "\n",
    "    print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred, zero_division=0))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred, zero_division=0))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MAIN PIPELINE\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(\"ðŸ§  Pre-trained model found! Loading existing model...\")\n",
    "    model = load_model(MODEL_PATH)\n",
    "    print(\"âœ… Model loaded successfully.\")\n",
    "\n",
    "    X, y = load_dataset()\n",
    "    X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "\n",
    "else:\n",
    "    print(\"âš™ï¸ Training new model...\")\n",
    "\n",
    "    X, y = load_dataset()\n",
    "    X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # âœ… FIX: Use dynamic frame length instead of undefined TARGET_FRAMES\n",
    "    TARGET_FRAMES = X_train.shape[1]\n",
    "\n",
    "    input_shape = (TARGET_FRAMES, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "    model = create_cnn_lstm_model(input_shape)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    model.save(MODEL_PATH)\n",
    "    print(\"âœ… Model saved!\")\n",
    "\n",
    "    evaluate_model(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d03fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "def start_detection():\n",
    "    messagebox.showinfo(\"Starting\", \"Real-time push-up detection starting...\")\n",
    "    run_detection()\n",
    "\n",
    "def show_metrics():\n",
    "    y_pred_raw = model.predict(X_test)\n",
    "    y_pred = (y_pred_raw > 0.5).astype(int)\n",
    "    msg = classification_report(y_test, y_pred)\n",
    "    messagebox.showinfo(\"Model Performance\", msg)\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"AI Push-up Trainer\")\n",
    "root.geometry(\"400x300\")\n",
    "\n",
    "tk.Button(root, text=\"Start Real-Time Detection\", command=start_detection).pack(pady=20)\n",
    "tk.Button(root, text=\"Show Model Metrics\", command=show_metrics).pack(pady=20)\n",
    "tk.Button(root, text=\"Exit\", command=root.destroy).pack(pady=20)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ee45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a); b = np.array(b); c = np.array(c)\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - \\\n",
    "              np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    if angle > 180:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "\n",
    "def run_detection():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    pose = mp_pose.Pose()\n",
    "\n",
    "    counter = 0\n",
    "    stage = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            lm = results.pose_landmarks.landmark\n",
    "\n",
    "            # Right arm joints\n",
    "            shoulder = [lm[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                        lm[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            elbow = [lm[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                     lm[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            wrist = [lm[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                     lm[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "\n",
    "            # Push-up logic\n",
    "            if angle < 90:\n",
    "                stage = \"down\"\n",
    "            if angle > 160 and stage == \"down\":\n",
    "                stage = \"up\"\n",
    "                counter += 1\n",
    "\n",
    "            cv2.putText(frame, f'Reps: {counter}', (10, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 3)\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        cv2.imshow(\"AI Push-Up Trainer\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedfbc20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Pushup Trainer Env",
   "language": "python",
   "name": "pushup-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
