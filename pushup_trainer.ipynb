{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a1633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d5462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"Dataset\"\n",
    "MODEL_PATH = \"pushup_cnn_lstm.h5\"\n",
    "IMG_SIZE = 64\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8abcd981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_video_frames_from_folder(folder, label):\n",
    "#     frames = []\n",
    "#     labels = []\n",
    "#     for filename in os.listdir(folder):\n",
    "#         file_path = os.path.join(folder, filename)\n",
    "#         cap = cv2.VideoCapture(file_path)\n",
    "#         frame_list = []\n",
    "#         while True:\n",
    "#             ret, frame = cap.read()\n",
    "#             if not ret:\n",
    "#                 break\n",
    "#             frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "#             frame = img_to_array(frame) / 255.0\n",
    "#             frame_list.append(frame)\n",
    "#         cap.release()\n",
    "#         if len(frame_list) > 0:\n",
    "#             frames.append(frame_list)\n",
    "#             labels.append(label)\n",
    "#     return frames, labels\n",
    "\n",
    "# def load_dataset():\n",
    "#     print(\"ðŸ“‚ Loading dataset...\")\n",
    "#     correct_frames, correct_labels = load_video_frames_from_folder(os.path.join(DATASET_PATH, \"Correct sequence\"), 1)\n",
    "#     wrong_frames, wrong_labels = load_video_frames_from_folder(os.path.join(DATASET_PATH, \"Wrong sequence\"), 0)\n",
    "\n",
    "#     frames = correct_frames + wrong_frames\n",
    "#     labels = correct_labels + wrong_labels\n",
    "\n",
    "#     # Pad/truncate sequences to same length\n",
    "#     max_len = max(len(f) for f in frames)\n",
    "#     X = np.zeros((len(frames), max_len, IMG_SIZE, IMG_SIZE, 3))\n",
    "#     for i, seq in enumerate(frames):\n",
    "#         for j in range(min(len(seq), max_len)):\n",
    "#             X[i, j] = seq[j]\n",
    "#     y = np.array(labels)\n",
    "#     print(\"âœ… Dataset loaded successfully.\")\n",
    "#     return X, y\n",
    "\n",
    "TARGET_FRAMES = 60   # or whatever number you want\n",
    "\n",
    "def reduce_frames(frame_list, target_frames=TARGET_FRAMES):\n",
    "    total = len(frame_list)\n",
    "    indices = np.linspace(0, total - 1, target_frames).astype(int)\n",
    "    reduced = [frame_list[i] for i in indices]\n",
    "    return np.array(reduced)\n",
    "\n",
    "\n",
    "def load_video_frames_from_folder(folder, label):\n",
    "    frames, labels = [], []\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        cap = cv2.VideoCapture(file_path)\n",
    "        extracted = []\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "            frame = img_to_array(frame) / 255.0\n",
    "            extracted.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        if len(extracted) >= 5:\n",
    "            frames.append(reduce_frames(extracted))\n",
    "            labels.append(label)\n",
    "\n",
    "    return frames, labels\n",
    "\n",
    "\n",
    "# def load_dataset():\n",
    "#     print(\"ðŸ“‚ Loading dataset...\")\n",
    "\n",
    "#     correct_frames, correct_labels = load_video_frames_from_folder(\n",
    "#         os.path.join(DATASET_PATH, \"Correct sequence\"), 1)\n",
    "\n",
    "#     wrong_frames, wrong_labels = load_video_frames_from_folder(\n",
    "#         os.path.join(DATASET_PATH, \"Wrong sequence\"), 0)\n",
    "\n",
    "#     X = np.array(correct_frames + wrong_frames)\n",
    "#     y = np.array(correct_labels + wrong_labels)\n",
    "\n",
    "#     print(\"New X shape:\", X.shape)  # (N, 30, 64, 64, 3)\n",
    "#     print(\"Unique labels:\", set(y))\n",
    "\n",
    "#     print(\"âœ… Dataset loaded successfully.\")\n",
    "#     return X, y\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    print(\"ðŸ“‚ Loading dataset...\")\n",
    "\n",
    "    # Load raw frames\n",
    "    correct_frames, correct_labels = load_video_frames_from_folder(\n",
    "        os.path.join(DATASET_PATH, \"Correct sequence\"), 1)\n",
    "\n",
    "    wrong_frames, wrong_labels = load_video_frames_from_folder(\n",
    "        os.path.join(DATASET_PATH, \"Wrong sequence\"), 0)\n",
    "\n",
    "    frames = correct_frames + wrong_frames\n",
    "    labels = correct_labels + wrong_labels\n",
    "\n",
    "    # -----------------------------\n",
    "    # âš ï¸ DYNAMIC FRAME HANDLING\n",
    "    # -----------------------------\n",
    "    # If model exists â†’ get expected frame count from model\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        print(\"ðŸ§  Pretrained model detected â†’ using its input sequence length.\")\n",
    "        model = load_model(MODEL_PATH)\n",
    "        max_len = model.input_shape[1]     # LSTM expected timesteps\n",
    "        print(f\"Model expects {max_len} frames.\")\n",
    "    else:\n",
    "        print(\"ðŸ“Œ No pretrained model â†’ using longest video sequence.\")\n",
    "        max_len = max(len(f) for f in frames)\n",
    "        print(f\"Max frame length found: {max_len}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # PAD / TRUNCATE EACH VIDEO\n",
    "    # -----------------------------\n",
    "    X = np.zeros((len(frames), max_len, IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "    for i, seq in enumerate(frames):\n",
    "        seq_len = len(seq)\n",
    "\n",
    "        if seq_len >= max_len:\n",
    "            # truncate extra frames\n",
    "            X[i] = np.array(seq[:max_len])\n",
    "        else:\n",
    "            # pad remaining frames with zeros\n",
    "            X[i, :seq_len] = np.array(seq)\n",
    "\n",
    "    y = np.array(labels)\n",
    "\n",
    "    print(\"New X shape:\", X.shape)\n",
    "    print(\"Unique labels:\", set(y))\n",
    "    print(\"âœ… Dataset loaded successfully.\\n\")\n",
    "\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a96ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=input_shape),\n",
    "        TimeDistributed(MaxPooling2D((2, 2))),\n",
    "\n",
    "        TimeDistributed(Conv2D(64, (3, 3), activation='relu')),\n",
    "        TimeDistributed(MaxPooling2D((2, 2))),\n",
    "\n",
    "        TimeDistributed(Flatten()),\n",
    "        LSTM(64, return_sequences=False),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccbfa044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Pre-trained model found! Loading existing model...\n",
      "âœ… Model loaded successfully.\n",
      "ðŸ“‚ Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Pretrained model detected â†’ using its input sequence length.\n",
      "Model expects 20 frames.\n",
      "New X shape: (100, 20, 64, 64, 3)\n",
      "Unique labels: {0, 1}\n",
      "âœ… Dataset loaded successfully.\n",
      "\n",
      "\n",
      "ðŸ“Š Evaluating Model...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [20, 40]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 44\u001b[0m\n\u001b[0;32m     38\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m shuffle(X, y, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     40\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     41\u001b[0m         X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     42\u001b[0m     )\n\u001b[1;32m---> 44\u001b[0m     \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâš™ï¸ Training new model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, X_test, y_test)\u001b[0m\n\u001b[0;32m     16\u001b[0m y_pred_raw \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (y_pred_raw \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision:\u001b[39m\u001b[38;5;124m\"\u001b[39m, precision_score(y_test, y_pred, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall:\u001b[39m\u001b[38;5;124m\"\u001b[39m, recall_score(y_test, y_pred, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Sajal Aggarwal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Sajal Aggarwal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Sajal Aggarwal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sajal Aggarwal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [20, 40]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "from sklearn.utils import shuffle   # âœ… FIX: Now imported properly\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    print(\"\\nðŸ“Š Evaluating Model...\")\n",
    "\n",
    "    # Predict\n",
    "    y_pred_raw = model.predict(X_test).reshape(-1)\n",
    "    y_pred = (y_pred_raw > 0.5).astype(int)\n",
    "\n",
    "    print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred, zero_division=0))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred, zero_division=0))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "# MAIN PIPELINE\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(\"ðŸ§  Pre-trained model found! Loading existing model...\")\n",
    "    model = load_model(MODEL_PATH)\n",
    "    print(\"âœ… Model loaded successfully.\")\n",
    "\n",
    "    X, y = load_dataset()\n",
    "    X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "\n",
    "else:\n",
    "    print(\"âš™ï¸ Training new model...\")\n",
    "\n",
    "    X, y = load_dataset()\n",
    "    X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # âœ… FIX: Use dynamic frame length instead of undefined TARGET_FRAMES\n",
    "    TARGET_FRAMES = X_train.shape[1]\n",
    "\n",
    "    input_shape = (TARGET_FRAMES, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "    model = create_cnn_lstm_model(input_shape)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    model.save(MODEL_PATH)\n",
    "    print(\"âœ… Model saved!\")\n",
    "\n",
    "    evaluate_model(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d03fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "def start_detection():\n",
    "    messagebox.showinfo(\"Starting\", \"Real-time push-up detection starting...\")\n",
    "    run_detection()\n",
    "\n",
    "def show_metrics():\n",
    "    y_pred_raw = model.predict(X_test)\n",
    "    y_pred = (y_pred_raw > 0.5).astype(int)\n",
    "    msg = classification_report(y_test, y_pred)\n",
    "    messagebox.showinfo(\"Model Performance\", msg)\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"AI Push-up Trainer\")\n",
    "root.geometry(\"400x300\")\n",
    "\n",
    "tk.Button(root, text=\"Start Real-Time Detection\", command=start_detection).pack(pady=20)\n",
    "tk.Button(root, text=\"Show Model Metrics\", command=show_metrics).pack(pady=20)\n",
    "tk.Button(root, text=\"Exit\", command=root.destroy).pack(pady=20)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ee45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a); b = np.array(b); c = np.array(c)\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - \\\n",
    "              np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    if angle > 180:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "\n",
    "def run_detection():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    pose = mp_pose.Pose()\n",
    "\n",
    "    counter = 0\n",
    "    stage = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            lm = results.pose_landmarks.landmark\n",
    "\n",
    "            # Right arm joints\n",
    "            shoulder = [lm[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                        lm[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            elbow = [lm[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                     lm[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            wrist = [lm[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                     lm[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "\n",
    "            # Push-up logic\n",
    "            if angle < 90:\n",
    "                stage = \"down\"\n",
    "            if angle > 160 and stage == \"down\":\n",
    "                stage = \"up\"\n",
    "                counter += 1\n",
    "\n",
    "            cv2.putText(frame, f'Reps: {counter}', (10, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 3)\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        cv2.imshow(\"AI Push-Up Trainer\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9766790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Pushup Trainer Env",
   "language": "python",
   "name": "pushup-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
